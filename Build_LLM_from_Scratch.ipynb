{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPokFX+E1k56yH5IIoKIezy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekjumar20/Build-LLM-From-Scratch/blob/main/Build_LLM_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X8q9l6AUGb0",
        "outputId": "2eb44180-40cf-497f-d862-46e3c934b2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n",
            "tiktoken version: 0.9.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm6gPAaYUKIT",
        "outputId": "3e2e2cab-932e-4cda-b512-fb1c053b5dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20701\n",
            "The Verdict\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item for item in preprocessed if item]\n",
        "print(preprocessed[:38])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pShTjoLXYTeg",
        "outputId": "4e82fcb5-835b-4a09-90f0-671d4d2d9787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', ' ', 'Verdict', '\\n', 'I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius', '--', 'though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '--', 'so', ' ', 'it', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of tokens:\", len(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSqPaP_eYwJa",
        "outputId": "2d61f70e-332d-4fe2-ff7e-a34e301301ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 8443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny_4ke3yYzrB",
        "outputId": "d23a9ec5-c34c-47d1-a1ab-1a8d37f3d478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1152"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(set(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DWo75QF3ZMoy",
        "outputId": "35030c57-e699-446a-fa28-9c7dd24c107b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '--',\n",
              " '.',\n",
              " '1',\n",
              " '1930',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'Ah',\n",
              " 'Among',\n",
              " 'And',\n",
              " 'Are',\n",
              " 'Arrt',\n",
              " 'As',\n",
              " 'At',\n",
              " 'Be',\n",
              " 'Begin',\n",
              " 'Burlington',\n",
              " 'But',\n",
              " 'By',\n",
              " 'Carlo',\n",
              " 'Chicago',\n",
              " 'Claude',\n",
              " 'Come',\n",
              " 'Croft',\n",
              " 'Destroyed',\n",
              " 'Devonshire',\n",
              " 'Don',\n",
              " 'Dubarry',\n",
              " 'Emperors',\n",
              " 'Florence',\n",
              " 'For',\n",
              " 'Gallery',\n",
              " 'Gideon',\n",
              " 'Gisburn',\n",
              " 'Gisburns',\n",
              " 'Grafton',\n",
              " 'Greek',\n",
              " 'Grindle',\n",
              " 'Grindles',\n",
              " 'HAD',\n",
              " 'Had',\n",
              " 'Hang',\n",
              " 'Has',\n",
              " 'He',\n",
              " 'Her',\n",
              " 'Hermia',\n",
              " 'His',\n",
              " 'How',\n",
              " 'I',\n",
              " 'If',\n",
              " 'In',\n",
              " 'It',\n",
              " 'Jack',\n",
              " 'January',\n",
              " 'Jove',\n",
              " 'Just',\n",
              " 'Lord',\n",
              " 'Made',\n",
              " 'Miss',\n",
              " 'Money',\n",
              " 'Monte',\n",
              " 'Moon-dancers',\n",
              " 'Mr',\n",
              " 'Mrs',\n",
              " 'My',\n",
              " 'Never',\n",
              " 'No',\n",
              " 'Now',\n",
              " 'Nutley',\n",
              " 'Of',\n",
              " 'Oh',\n",
              " 'On',\n",
              " 'Once',\n",
              " 'Only',\n",
              " 'Or',\n",
              " 'Perhaps',\n",
              " 'Poor',\n",
              " 'Professional',\n",
              " 'Renaissance',\n",
              " 'Return',\n",
              " 'Rickham',\n",
              " 'Riviera',\n",
              " 'Rome',\n",
              " 'Russian',\n",
              " 'Sevres',\n",
              " 'She',\n",
              " 'States',\n",
              " 'Stroud',\n",
              " 'Strouds',\n",
              " 'Suddenly',\n",
              " 'That',\n",
              " 'The',\n",
              " 'Then',\n",
              " 'There',\n",
              " 'They',\n",
              " 'This',\n",
              " 'Those',\n",
              " 'Though',\n",
              " 'Thwing',\n",
              " 'Thwings',\n",
              " 'To',\n",
              " 'United',\n",
              " 'Usually',\n",
              " 'Venetian',\n",
              " 'Verdict',\n",
              " 'Victor',\n",
              " 'Was',\n",
              " 'We',\n",
              " 'Well',\n",
              " 'What',\n",
              " 'When',\n",
              " 'Why',\n",
              " 'Yes',\n",
              " 'You',\n",
              " '_',\n",
              " 'a',\n",
              " 'abdication',\n",
              " 'able',\n",
              " 'about',\n",
              " 'above',\n",
              " 'abruptly',\n",
              " 'absolute',\n",
              " 'absorbed',\n",
              " 'absurdity',\n",
              " 'academic',\n",
              " 'accuse',\n",
              " 'accustomed',\n",
              " 'across',\n",
              " 'activity',\n",
              " 'add',\n",
              " 'added',\n",
              " 'admirers',\n",
              " 'adopted',\n",
              " 'adulation',\n",
              " 'advance',\n",
              " 'aesthetic',\n",
              " 'affect',\n",
              " 'afraid',\n",
              " 'after',\n",
              " 'afterward',\n",
              " 'again',\n",
              " 'ago',\n",
              " 'ah',\n",
              " 'air',\n",
              " 'alive',\n",
              " 'all',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'always',\n",
              " 'am',\n",
              " 'amazement',\n",
              " 'amid',\n",
              " 'among',\n",
              " 'amplest',\n",
              " 'amusing',\n",
              " 'an',\n",
              " 'and',\n",
              " 'another',\n",
              " 'answer',\n",
              " 'answered',\n",
              " 'any',\n",
              " 'anything',\n",
              " 'anywhere',\n",
              " 'apparent',\n",
              " 'apparently',\n",
              " 'appearance',\n",
              " 'appeared',\n",
              " 'apply',\n",
              " 'appointed',\n",
              " 'are',\n",
              " 'areas',\n",
              " 'arm',\n",
              " 'arm-chair',\n",
              " 'arm-chairs',\n",
              " 'arms',\n",
              " 'art',\n",
              " 'articles',\n",
              " 'artist',\n",
              " 'as',\n",
              " 'aside',\n",
              " 'asked',\n",
              " 'at',\n",
              " 'atmosphere',\n",
              " 'atom',\n",
              " 'attack',\n",
              " 'attention',\n",
              " 'attitude',\n",
              " 'audacities',\n",
              " 'away',\n",
              " 'awful',\n",
              " 'axioms',\n",
              " 'azaleas',\n",
              " 'back',\n",
              " 'background',\n",
              " 'balance',\n",
              " 'balancing',\n",
              " 'balustraded',\n",
              " 'basking',\n",
              " 'bath-rooms',\n",
              " 'be',\n",
              " 'beaming',\n",
              " 'beanstalk',\n",
              " 'bear',\n",
              " 'beard',\n",
              " 'beauty',\n",
              " 'became',\n",
              " 'because',\n",
              " 'becoming',\n",
              " 'bed',\n",
              " 'been',\n",
              " 'before',\n",
              " 'began',\n",
              " 'begun',\n",
              " 'behind',\n",
              " 'being',\n",
              " 'believed',\n",
              " 'beneath',\n",
              " 'bespoke',\n",
              " 'better',\n",
              " 'between',\n",
              " 'big',\n",
              " 'bits',\n",
              " 'bitterness',\n",
              " 'blocked',\n",
              " 'born',\n",
              " 'borne',\n",
              " 'boudoir',\n",
              " 'bravura',\n",
              " 'break',\n",
              " 'breaking',\n",
              " 'breathing',\n",
              " 'bric-a-brac',\n",
              " 'briefly',\n",
              " 'brings',\n",
              " 'bronzes',\n",
              " 'brought',\n",
              " 'brown',\n",
              " 'brush',\n",
              " 'bull',\n",
              " 'business',\n",
              " 'but',\n",
              " 'buying',\n",
              " 'by',\n",
              " 'called',\n",
              " 'came',\n",
              " 'can',\n",
              " 'canvas',\n",
              " 'canvases',\n",
              " 'cards',\n",
              " 'care',\n",
              " 'career',\n",
              " 'caught',\n",
              " 'central',\n",
              " 'chair',\n",
              " 'chap',\n",
              " 'characteristic',\n",
              " 'charming',\n",
              " 'cheap',\n",
              " 'check',\n",
              " 'cheeks',\n",
              " 'chest',\n",
              " 'chimney-piece',\n",
              " 'chucked',\n",
              " 'cigar',\n",
              " 'cigarette',\n",
              " 'cigars',\n",
              " 'circulation',\n",
              " 'circumstance',\n",
              " 'circus-clown',\n",
              " 'claimed',\n",
              " 'clasping',\n",
              " 'clear',\n",
              " 'cleverer',\n",
              " 'close',\n",
              " 'clue',\n",
              " 'coat',\n",
              " 'collapsed',\n",
              " 'colour',\n",
              " 'come',\n",
              " 'comfortable',\n",
              " 'coming',\n",
              " 'companion',\n",
              " 'compared',\n",
              " 'complex',\n",
              " 'confident',\n",
              " 'congesting',\n",
              " 'conjugal',\n",
              " 'constraint',\n",
              " 'consummate',\n",
              " 'contended',\n",
              " 'continued',\n",
              " 'copyright',\n",
              " 'corner',\n",
              " 'corrected',\n",
              " 'could',\n",
              " 'couldn',\n",
              " 'count',\n",
              " 'countenance',\n",
              " 'countries',\n",
              " 'couple',\n",
              " 'course',\n",
              " 'covered',\n",
              " 'craft',\n",
              " 'cried',\n",
              " 'crossed',\n",
              " 'crowned',\n",
              " 'crumbled',\n",
              " 'cry',\n",
              " 'cured',\n",
              " 'curiosity',\n",
              " 'curious',\n",
              " 'current',\n",
              " 'curtains',\n",
              " 'd',\n",
              " 'dabble',\n",
              " 'damask',\n",
              " 'dark',\n",
              " 'dashed',\n",
              " 'day',\n",
              " 'days',\n",
              " 'dead',\n",
              " 'deadening',\n",
              " 'dear',\n",
              " 'deep',\n",
              " 'deerhound',\n",
              " 'degree',\n",
              " 'delicate',\n",
              " 'demand',\n",
              " 'denied',\n",
              " 'deploring',\n",
              " 'deprecating',\n",
              " 'deprecatingly',\n",
              " 'desire',\n",
              " 'destroyed',\n",
              " 'destruction',\n",
              " 'desultory',\n",
              " 'detail',\n",
              " 'diagnosis',\n",
              " 'did',\n",
              " 'didn',\n",
              " 'died',\n",
              " 'dim',\n",
              " 'dimmest',\n",
              " 'dingy',\n",
              " 'dining-room',\n",
              " 'disarming',\n",
              " 'discovery',\n",
              " 'discrimination',\n",
              " 'discussion',\n",
              " 'disdain',\n",
              " 'disdained',\n",
              " 'disease',\n",
              " 'disguised',\n",
              " 'display',\n",
              " 'dissatisfied',\n",
              " 'distinguished',\n",
              " 'distract',\n",
              " 'divert',\n",
              " 'do',\n",
              " 'doesn',\n",
              " 'doing',\n",
              " 'domain',\n",
              " 'domestic',\n",
              " 'don',\n",
              " 'done',\n",
              " 'donkey',\n",
              " 'down',\n",
              " 'dozen',\n",
              " 'dragged',\n",
              " 'drawing-room',\n",
              " 'drawing-rooms',\n",
              " 'drawn',\n",
              " 'dress-closets',\n",
              " 'drew',\n",
              " 'dropped',\n",
              " 'each',\n",
              " 'earth',\n",
              " 'ease',\n",
              " 'easel',\n",
              " 'easy',\n",
              " 'echoed',\n",
              " 'economy',\n",
              " 'effect',\n",
              " 'effects',\n",
              " 'efforts',\n",
              " 'egregious',\n",
              " 'eighteenth-century',\n",
              " 'elbow',\n",
              " 'elegant',\n",
              " 'else',\n",
              " 'embarrassed',\n",
              " 'enabled',\n",
              " 'end',\n",
              " 'endless',\n",
              " 'enjoy',\n",
              " 'enlightenment',\n",
              " 'enough',\n",
              " 'ensuing',\n",
              " 'equally',\n",
              " 'equanimity',\n",
              " 'escape',\n",
              " 'established',\n",
              " 'etching',\n",
              " 'even',\n",
              " 'event',\n",
              " 'ever',\n",
              " 'everlasting',\n",
              " 'every',\n",
              " 'exasperated',\n",
              " 'except',\n",
              " 'excuse',\n",
              " 'excusing',\n",
              " 'existed',\n",
              " 'expected',\n",
              " 'exquisite',\n",
              " 'exquisitely',\n",
              " 'extenuation',\n",
              " 'exterminating',\n",
              " 'extracting',\n",
              " 'eye',\n",
              " 'eyebrows',\n",
              " 'eyes',\n",
              " 'face',\n",
              " 'faces',\n",
              " 'fact',\n",
              " 'faded',\n",
              " 'failed',\n",
              " 'failure',\n",
              " 'fair',\n",
              " 'faith',\n",
              " 'false',\n",
              " 'familiar',\n",
              " 'famille-verte',\n",
              " 'fancy',\n",
              " 'fashionable',\n",
              " 'fate',\n",
              " 'feather',\n",
              " 'feet',\n",
              " 'fell',\n",
              " 'fellow',\n",
              " 'felt',\n",
              " 'few',\n",
              " 'fewer',\n",
              " 'finality',\n",
              " 'find',\n",
              " 'fingers',\n",
              " 'first',\n",
              " 'fit',\n",
              " 'fitting',\n",
              " 'five',\n",
              " 'flash',\n",
              " 'flashed',\n",
              " 'florid',\n",
              " 'flowers',\n",
              " 'fluently',\n",
              " 'flung',\n",
              " 'follow',\n",
              " 'followed',\n",
              " 'fond',\n",
              " 'footstep',\n",
              " 'for',\n",
              " 'forced',\n",
              " 'forcing',\n",
              " 'forehead',\n",
              " 'foreign',\n",
              " 'foreseen',\n",
              " 'forgive',\n",
              " 'forgotten',\n",
              " 'form',\n",
              " 'formed',\n",
              " 'forming',\n",
              " 'forward',\n",
              " 'fostered',\n",
              " 'found',\n",
              " 'foundations',\n",
              " 'fragment',\n",
              " 'fragments',\n",
              " 'frame',\n",
              " 'frames',\n",
              " 'frequently',\n",
              " 'friend',\n",
              " 'from',\n",
              " 'full',\n",
              " 'fullest',\n",
              " 'furiously',\n",
              " 'furrowed',\n",
              " 'garlanded',\n",
              " 'garlands',\n",
              " 'gave',\n",
              " 'genial',\n",
              " 'genius',\n",
              " 'gesture',\n",
              " 'get',\n",
              " 'getting',\n",
              " 'give',\n",
              " 'given',\n",
              " 'glad',\n",
              " 'glanced',\n",
              " 'glimpse',\n",
              " 'gloried',\n",
              " 'glory',\n",
              " 'go',\n",
              " 'going',\n",
              " 'gone',\n",
              " 'good',\n",
              " 'good-breeding',\n",
              " 'good-humoured',\n",
              " 'got',\n",
              " 'grace',\n",
              " 'gradually',\n",
              " 'gray',\n",
              " 'grayish',\n",
              " 'great',\n",
              " 'greatest',\n",
              " 'greatness',\n",
              " 'grew',\n",
              " 'groping',\n",
              " 'growing',\n",
              " 'had',\n",
              " 'hadn',\n",
              " 'hair',\n",
              " 'half',\n",
              " 'half-light',\n",
              " 'half-mechanically',\n",
              " 'hall',\n",
              " 'hand',\n",
              " 'hands',\n",
              " 'handsome',\n",
              " 'hanging',\n",
              " 'happen',\n",
              " 'happened',\n",
              " 'hard',\n",
              " 'hardly',\n",
              " 'has',\n",
              " 'have',\n",
              " 'haven',\n",
              " 'having',\n",
              " 'he',\n",
              " 'head',\n",
              " 'hear',\n",
              " 'heard',\n",
              " 'heart',\n",
              " 'height',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hermit',\n",
              " 'herself',\n",
              " 'hesitations',\n",
              " 'hide',\n",
              " 'high',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'hint',\n",
              " 'his',\n",
              " 'history',\n",
              " 'holding',\n",
              " 'home',\n",
              " 'honour',\n",
              " 'hooded',\n",
              " 'hostess',\n",
              " 'hot-house',\n",
              " 'hour',\n",
              " 'hours',\n",
              " 'house',\n",
              " 'how',\n",
              " 'hung',\n",
              " 'husband',\n",
              " 'idea',\n",
              " 'idle',\n",
              " 'idling',\n",
              " 'if',\n",
              " 'immediately',\n",
              " 'in',\n",
              " 'incense',\n",
              " 'indifferent',\n",
              " 'inevitable',\n",
              " 'inevitably',\n",
              " 'inflexible',\n",
              " 'insensible',\n",
              " 'insignificant',\n",
              " 'instinctively',\n",
              " 'instructive',\n",
              " 'interesting',\n",
              " 'into',\n",
              " 'ironic',\n",
              " 'irony',\n",
              " 'irrelevance',\n",
              " 'irrevocable',\n",
              " 'is',\n",
              " 'it',\n",
              " 'its',\n",
              " 'itself',\n",
              " 'jardiniere',\n",
              " 'jealousy',\n",
              " 'just',\n",
              " 'keep',\n",
              " 'kept',\n",
              " 'kind',\n",
              " 'knees',\n",
              " 'knew',\n",
              " 'know',\n",
              " 'known',\n",
              " 'laid',\n",
              " 'lair',\n",
              " 'landing',\n",
              " 'language',\n",
              " 'last',\n",
              " 'late',\n",
              " 'later',\n",
              " 'latter',\n",
              " 'laugh',\n",
              " 'laughed',\n",
              " 'lay',\n",
              " 'leading',\n",
              " 'lean',\n",
              " 'learned',\n",
              " 'least',\n",
              " 'leathery',\n",
              " 'leave',\n",
              " 'led',\n",
              " 'left',\n",
              " 'leisure',\n",
              " 'lends',\n",
              " 'lent',\n",
              " 'let',\n",
              " 'lies',\n",
              " 'life',\n",
              " 'life-likeness',\n",
              " 'lift',\n",
              " 'lifted',\n",
              " 'light',\n",
              " 'lightly',\n",
              " 'like',\n",
              " 'liked',\n",
              " 'line',\n",
              " 'lines',\n",
              " 'lingered',\n",
              " 'lips',\n",
              " 'lit',\n",
              " 'little',\n",
              " 'live',\n",
              " 'll',\n",
              " 'loathing',\n",
              " 'long',\n",
              " 'longed',\n",
              " 'longer',\n",
              " 'look',\n",
              " 'looked',\n",
              " 'looking',\n",
              " 'lose',\n",
              " 'loss',\n",
              " 'lounging',\n",
              " 'lovely',\n",
              " 'lucky',\n",
              " 'lump',\n",
              " 'luncheon-table',\n",
              " 'luxury',\n",
              " 'lying',\n",
              " 'made',\n",
              " 'make',\n",
              " 'man',\n",
              " 'manage',\n",
              " 'managed',\n",
              " 'mantel-piece',\n",
              " 'marble',\n",
              " 'married',\n",
              " 'may',\n",
              " 'me',\n",
              " 'meant',\n",
              " 'mediocrity',\n",
              " 'medium',\n",
              " 'mentioned',\n",
              " 'mere',\n",
              " 'merely',\n",
              " 'met',\n",
              " 'might',\n",
              " 'mighty',\n",
              " 'millionaire',\n",
              " 'mine',\n",
              " 'minute',\n",
              " 'minutes',\n",
              " 'mirrors',\n",
              " 'modest',\n",
              " 'modesty',\n",
              " 'moment',\n",
              " 'money',\n",
              " 'monumental',\n",
              " 'mood',\n",
              " 'morbidly',\n",
              " 'more',\n",
              " 'most',\n",
              " 'mourn',\n",
              " 'mourned',\n",
              " 'moustache',\n",
              " 'moved',\n",
              " 'much',\n",
              " 'muddling',\n",
              " 'multiplied',\n",
              " 'murmur',\n",
              " 'muscles',\n",
              " 'must',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'mysterious',\n",
              " 'naive',\n",
              " 'native',\n",
              " 'near',\n",
              " 'nearly',\n",
              " 'negatived',\n",
              " 'nervous',\n",
              " 'nervousness',\n",
              " 'neutral',\n",
              " 'never',\n",
              " 'next',\n",
              " 'no',\n",
              " 'none',\n",
              " 'not',\n",
              " 'note',\n",
              " 'nothing',\n",
              " 'now',\n",
              " 'nymphs',\n",
              " 'oak',\n",
              " 'obituary',\n",
              " 'object',\n",
              " 'objects',\n",
              " 'occurred',\n",
              " 'oddly',\n",
              " 'of',\n",
              " 'off',\n",
              " 'often',\n",
              " 'oh',\n",
              " 'old',\n",
              " 'on',\n",
              " 'once',\n",
              " 'one',\n",
              " 'ones',\n",
              " 'only',\n",
              " 'onto',\n",
              " 'open',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'outline',\n",
              " 'oval',\n",
              " 'over',\n",
              " 'own',\n",
              " 'packed',\n",
              " 'page',\n",
              " 'paid',\n",
              " 'paint',\n",
              " 'painted',\n",
              " 'painter',\n",
              " 'painting',\n",
              " 'pale',\n",
              " 'paled',\n",
              " 'palm-trees',\n",
              " 'panel',\n",
              " 'panelling',\n",
              " 'pardonable',\n",
              " 'pardoned',\n",
              " 'part',\n",
              " 'passages',\n",
              " 'passing',\n",
              " 'past',\n",
              " 'pastels',\n",
              " 'pathos',\n",
              " 'patient',\n",
              " 'people',\n",
              " 'perceptible',\n",
              " 'perfect',\n",
              " 'persistence',\n",
              " 'persuasively',\n",
              " 'phrase',\n",
              " 'picture',\n",
              " 'pictures',\n",
              " 'pines',\n",
              " 'pink',\n",
              " 'place',\n",
              " 'placed',\n",
              " 'plain',\n",
              " 'platitudes',\n",
              " 'pleased',\n",
              " 'pockets',\n",
              " 'point',\n",
              " 'poised',\n",
              " 'poor',\n",
              " 'portrait',\n",
              " 'posing',\n",
              " 'possessed',\n",
              " 'poverty',\n",
              " 'predicted',\n",
              " 'preliminary',\n",
              " 'presenting',\n",
              " 'prestidigitation',\n",
              " 'pretty',\n",
              " 'previous',\n",
              " 'price',\n",
              " 'pride',\n",
              " 'princely',\n",
              " 'prism',\n",
              " 'problem',\n",
              " 'proclaiming',\n",
              " 'prodigious',\n",
              " 'profusion',\n",
              " 'protest',\n",
              " 'prove',\n",
              " 'public',\n",
              " 'published',\n",
              " 'purblind',\n",
              " 'purely',\n",
              " 'pushed',\n",
              " 'put',\n",
              " 'qualities',\n",
              " 'quality',\n",
              " 'queerly',\n",
              " 'question',\n",
              " 'quickly',\n",
              " 'quietly',\n",
              " 'quite',\n",
              " 'quote',\n",
              " 'rain',\n",
              " 'raised',\n",
              " 'random',\n",
              " 'rather',\n",
              " 're',\n",
              " 'real',\n",
              " 'really',\n",
              " 'reared',\n",
              " 'reason',\n",
              " 'reassurance',\n",
              " 'recovering',\n",
              " 'recreated',\n",
              " 'reflected',\n",
              " 'reflection',\n",
              " 'regrets',\n",
              " 'relatively',\n",
              " 'remained',\n",
              " 'remember',\n",
              " 'reminded',\n",
              " 'repeating',\n",
              " 'represented',\n",
              " 'reproduction',\n",
              " 'resented',\n",
              " 'resolve',\n",
              " 'resources',\n",
              " 'rest',\n",
              " 'rich',\n",
              " 'ridiculous',\n",
              " 'robbed',\n",
              " 'romantic',\n",
              " 'room',\n",
              " 'rose',\n",
              " 'rs',\n",
              " 'rule',\n",
              " 'run',\n",
              " 's',\n",
              " 'said',\n",
              " 'same',\n",
              " 'satisfaction',\n",
              " 'savour',\n",
              " 'saw',\n",
              " 'say',\n",
              " 'saying',\n",
              " 'says',\n",
              " 'scorn',\n",
              " 'scornful',\n",
              " 'secret',\n",
              " 'see',\n",
              " 'seemed',\n",
              " 'seen',\n",
              " 'self-confident',\n",
              " 'send',\n",
              " 'sensation',\n",
              " 'sensitive',\n",
              " 'sent',\n",
              " 'serious',\n",
              " 'set',\n",
              " 'sex',\n",
              " 'shade',\n",
              " 'shaking',\n",
              " 'shall',\n",
              " 'she',\n",
              " 'shirked',\n",
              " 'short',\n",
              " 'shorter',\n",
              " 'should',\n",
              " 'shoulder',\n",
              " 'shoulders',\n",
              " 'show',\n",
              " 'showed',\n",
              " 'showy',\n",
              " 'shrug',\n",
              " 'shrugged',\n",
              " 'sight',\n",
              " 'sign',\n",
              " 'silent',\n",
              " 'silver',\n",
              " 'similar',\n",
              " 'simpleton',\n",
              " 'simplifications',\n",
              " 'simply',\n",
              " 'since',\n",
              " 'single',\n",
              " 'sitter',\n",
              " 'sitters',\n",
              " 'sketch',\n",
              " 'skill',\n",
              " 'slight',\n",
              " 'slightly',\n",
              " 'slowly',\n",
              " 'small',\n",
              " 'smile',\n",
              " 'smiling',\n",
              " 'sneer',\n",
              " 'so',\n",
              " 'solace',\n",
              " 'some',\n",
              " 'somebody',\n",
              " 'something',\n",
              " 'spacious',\n",
              " 'spaniel',\n",
              " 'speaking-tubes',\n",
              " 'speculations',\n",
              " 'spite',\n",
              " 'splash',\n",
              " 'square',\n",
              " 'stairs',\n",
              " 'stammer',\n",
              " 'stand',\n",
              " 'standing',\n",
              " 'started',\n",
              " 'stay',\n",
              " 'still',\n",
              " 'stocked',\n",
              " 'stood',\n",
              " 'stopped',\n",
              " 'stopping',\n",
              " 'straddling',\n",
              " 'straight',\n",
              " 'strain',\n",
              " 'straining',\n",
              " 'strange',\n",
              " 'straw',\n",
              " 'stream',\n",
              " 'stroke',\n",
              " 'strokes',\n",
              " 'strolled',\n",
              " 'strongest',\n",
              " 'strongly',\n",
              " 'struck',\n",
              " 'studio',\n",
              " 'stuff',\n",
              " 'subject',\n",
              " 'substantial',\n",
              " 'suburban',\n",
              " 'such',\n",
              " 'suddenly',\n",
              " 'suffered',\n",
              " 'sugar',\n",
              " 'suggested',\n",
              " 'sunburn',\n",
              " 'sunburnt',\n",
              " 'sunlit',\n",
              " 'superb',\n",
              " 'sure',\n",
              " 'surest',\n",
              " 'surface',\n",
              " 'surprise',\n",
              " 'surprised',\n",
              " 'surrounded',\n",
              " 'suspected',\n",
              " 'sweetly',\n",
              " 'sweetness',\n",
              " 'swelling',\n",
              " 'swept',\n",
              " 'swum',\n",
              " 't',\n",
              " 'table',\n",
              " 'take',\n",
              " 'taken',\n",
              " 'talking',\n",
              " 'tea',\n",
              " 'tears',\n",
              " 'technicalities',\n",
              " 'technique',\n",
              " 'tell',\n",
              " 'tells',\n",
              " 'tempting',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opOL2gvUZR_d",
        "outputId": "5743f4ea-9608-4d40-e400-0387a609a1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token:integer for integer,token in enumerate(all_words)}"
      ],
      "metadata": {
        "id": "XfKNQClObl7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(vocab.items()):\n",
        "    print(item)\n",
        "    if i >= 50:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWMukdYabrcn",
        "outputId": "543d82e2-cd90-4446-f948-4487ded6e948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('\\n', 0)\n",
            "(' ', 1)\n",
            "('!', 2)\n",
            "('\"', 3)\n",
            "(\"'\", 4)\n",
            "('(', 5)\n",
            "(')', 6)\n",
            "(',', 7)\n",
            "('--', 8)\n",
            "('.', 9)\n",
            "('1', 10)\n",
            "('1930', 11)\n",
            "(':', 12)\n",
            "(';', 13)\n",
            "('?', 14)\n",
            "('A', 15)\n",
            "('Ah', 16)\n",
            "('Among', 17)\n",
            "('And', 18)\n",
            "('Are', 19)\n",
            "('Arrt', 20)\n",
            "('As', 21)\n",
            "('At', 22)\n",
            "('Be', 23)\n",
            "('Begin', 24)\n",
            "('Burlington', 25)\n",
            "('But', 26)\n",
            "('By', 27)\n",
            "('Carlo', 28)\n",
            "('Chicago', 29)\n",
            "('Claude', 30)\n",
            "('Come', 31)\n",
            "('Croft', 32)\n",
            "('Destroyed', 33)\n",
            "('Devonshire', 34)\n",
            "('Don', 35)\n",
            "('Dubarry', 36)\n",
            "('Emperors', 37)\n",
            "('Florence', 38)\n",
            "('For', 39)\n",
            "('Gallery', 40)\n",
            "('Gideon', 41)\n",
            "('Gisburn', 42)\n",
            "('Gisburns', 43)\n",
            "('Grafton', 44)\n",
            "('Greek', 45)\n",
            "('Grindle', 46)\n",
            "('Grindles', 47)\n",
            "('HAD', 48)\n",
            "('Had', 49)\n",
            "('Hang', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [\n",
        "            item.strip() for item in preprocessed if item.strip()\n",
        "        ]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        # Replace spaces before the specified punctuations\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "fB8ggNpMcCuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWYlhr_bdBRd",
        "outputId": "26535b62-c430-40ef-f3b3-09f8a524aad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 60, 4, 867, 1008, 616, 547, 762, 7, 1148, 610, 7, 3, 72, 9, 42, 868, 1129, 770, 809, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tk7CdLsVdICc",
        "outputId": "33227da4-bf4f-4f28-c642-5ba80d948320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fwWsGx7hdYzu",
        "outputId": "4d79e754-3faa-4158-a6c5-e042cc071111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"'We shall not look upon its like again'?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka1XZ5KUdb9O",
        "outputId": "8bad30cc-8cc5-4862-e718-295abab2644c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 116, 892, 726, 656, 1074, 600, 642, 149, 4, 14]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([4, 116, 892, 726, 656, 1074, 600, 642, 149, 4, 14])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yFk9UBlNd1Qx",
        "outputId": "fc1a0846-1fe1-4838-a55d-c89f7ce8899a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"' We shall not look upon its like again'?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BytePair Encoding"
      ],
      "metadata": {
        "id": "8n7mPSi5eXhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyuu1Dw0eI7C",
        "outputId": "0fa22188-3512-42ec-dcf9-2a00183c9a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az-_mRI8enAc",
        "outputId": "9f053f0d-0d87-44ac-c499-1bd4e2f2ad3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "Uwq_fw7wetyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "     \"of someunknownPlace.\"\n",
        ")\n",
        "\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca0i5_uTgErq",
        "outputId": "ad88ecdf-d364-42f0-9051-9a2367aafc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5S2Cw6egJGy",
        "outputId": "0ba90375-fe71-4293-bd15-3ec927e74283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"Akwirw ier\", allowed_special={\"<|endoftext|>\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AELiqGn8gMYq",
        "outputId": "70b51e1a-e557-4b50-9176-ee021692724e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[33901, 86, 343, 86, 220, 959]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([33901])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ttEipiVZg_7d",
        "outputId": "b793f00a-eeec-4730-d479-b365eea9aceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ak'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from supplementary import create_dataloader_v1\n",
        "\n",
        "\n",
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "id": "RQYQeawThFYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d30322-c7f8-42b0-d0a3-72581c563d39"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[  464,  4643, 11600,   198],\n",
            "        [   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   198],\n",
            "        [ 3919,  1049,  5975,   284]])\n",
            "\n",
            "Targets:\n",
            " tensor([[ 4643, 11600,   198,    40],\n",
            "        [  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   198,  3919],\n",
            "        [ 1049,  5975,   284,   502]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DG0w3Dpsj-zk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}